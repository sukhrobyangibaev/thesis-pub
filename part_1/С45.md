# C4.5 algorithm

ID3 disadvantages:

- attributes must be nominal values
- must not include missing data
- tend to fall into overfitting

C4.5 improbements:

- include continuous data
- can handle missing data

> Trick is we will convert continuous features into categorical

# Example

| Day | Outlook | Temp. | Humidity | Wind   | Decision |
| --- | ------- | ----- | -------- | ------ | -------- |
| 1   | 85      | 85    | High     | Weak   | No       |
| 2   | 80      | 90    | High     | Strong | No       |
| 3   | 83      | 78    | High     | Weak   | Yes      |
| 4   | 70      | 96    | High     | Weak   | Yes      |
| 5   | 68      | 80    | Normal   | Weak   | Yes      |
| 6   | 65      | 70    | Normal   | Strong | No       |
| 7   | 64      | 65    | Normal   | Strong | Yes      |
| 8   | 72      | 95    | High     | Weak   | No       |
| 9   | 69      | 70    | Normal   | Weak   | Yes      |
| 10  | 75      | 80    | Normal   | Weak   | Yes      |
| 11  | 75      | 70    | Normal   | Strong | Yes      |
| 12  | 72      | 90    | High     | Strong | Yes      |
| 13  | 81      | 75    | Normal   | Weak   | Yes      |
| 14  | 71      | 80    | High     | Strong | No       |

---

> We need to calculate the global entropy first. Decision column consists of 14 instances and includes two labels: yes and no. There are 9 decisions labeled yes, and 5 decisions labeled no.

<br/>

$$Entropy(Decision) = – P(Yes) * \log_{2}^{P(Yes)} – P(No) * \log_{2}^{P(No)}$$

<br/>

$Entropy(Decision) = – (9/14) * \log_{2}^{9/14} – (5/14) * \log_{2}^{5/14} = 0.940$

---

> Next we need to calculate Gain Ratios.

### **Wind** attribute

> Wind is a nominal attribute. Its possible values are weak and strong.

> There are 8 weak wind instances. 2 of them are concluded as no, 6 of them are concluded as yes.

$Entropy(Decision|Wind=Weak) = – P(Yes) * \log_{2}^{P(Yes)} – P(No) * \log_{2}^{P(No)} = – (2/8) * \log_{2}^{2/8} – (6/8) * \log_{2}^{6/8} = 0.811$

> There are 6 weak wind instances. 3 of them are concluded as no, 3 of them are concluded as yes.

$Entropy(Decision|Wind=Strong) = – (3/6) * \log_{2}^{3/6} – (3/6) * \log_{2}^{3/6} = 1$

> Calculate Gain

$$Gain(S, A) = Entropy(S)  – \sum_{i=1}^{n}  P(S|A) * Entropy(S|A) $$

$Gain(Decision, Wind) = Entropy(Decision) – ∑ ( p(Decision|Wind) * Entropy(Decision|Wind))$

$Gain(Decision, Wind) = Entropy(Decision) – [ P(Decision|Wind=Weak) * Entropy(Decision|Wind=Weak) ] + [ P(Decision|Wind=Strong) * Entropy(Decision|Wind=Strong) ]$

$Gain(Decision, Wind) = 0.940 – (8/14).(0.811) – (6/14).(1) = 0.940 – 0.463 – 0.428 = 0.049$

> There are 8 decisions for weak wind, and 6 decisions for strong wind.

$$SplitInfo(A) = -\sum_{i=1}^{n} \frac{D_i}{D} * \log_{2}^{\frac{D_i}{D}}$$

$SplitInfo(Decision, Wind) = -(8/14).log2(8/14) – (6/14).log2(6/14) = 0.461 + 0.524 = 0.985$

$$GainRatio(A) = Gain(A) / SplitInfo(A)$$

$GainRatio(Decision, Wind) = Gain(Decision, Wind) / SplitInfo(Decision, Wind) = 0.049 / 0.985 = 0.049$

---

### **Outlook** Attribute

> Same calculation as for **wind**

$GainRatio(Decision, Outlook) = 0.246/1.577 = 0.155$

---

### **Humidity** Attribute

> As an exception, humidity is a continuous attribute. We need to convert continuous values to nominal ones. C4.5 proposes to perform binary split based on a threshold value. Threshold should be a value which offers maximum gain for that attribute. Let’s focus on humidity attribute. Firstly, we need to sort humidity values smallest to largest.

| Day | Humidity | Decision |
| --- | -------- | -------- |
| 7   | 65       | Yes      |
| 6   | 70       | No       |
| 9   | 70       | Yes      |
| 11  | 70       | Yes      |
| 13  | 75       | Yes      |
| 3   | 78       | Yes      |
| 5   | 80       | Yes      |
| 10  | 80       | Yes      |
| 14  | 80       | No       |
| 1   | 85       | No       |
| 2   | 90       | No       |
| 12  | 90       | Yes      |
| 8   | 95       | No       |
| 4   | 96       | Yes      |

> Now, we need to iterate on all humidity values and seperate dataset into two parts as instances less than or equal to current value, and instances greater than the current value. We would calculate the gain or gain ratio for every step. The value which maximizes the gain would be the threshold.

> Check **65** as a threshold for humidity

<= 65

$Entropy(Decision|Humidity<=65) = – P(Yes) * \log_{2}^{P(Yes)} – P(No) * \log_{2}^{P(No)} = -(0/1).log2(0/1) – (1/1).log2(1/1) = 0$

\> 65

$Entropy(Decision|Humidity>65) = -(5/13) * log2(5/13) – (8/13) * log2(8/13) =0.530 + 0.431 = 0.961$

$Gain(Decision, Humidity <> 65) = 0.940 – (1/14) * 0 – (13/14) * (0.961) = 0.048$

$SplitInfo(Decision, Humidity<> 65) = -(1/14) * log2(1/14) -(13/14) * log2(13/14) = 0.371$

$GainRatio(Decision, Humidity<> 65) = 0.126$

> Check **70** as a threshold for humidity$

$Entropy(Decision|Humidity<=70) = – (1/4) * log2(1/4) – (3/4) * log2(3/4) = 0.811$

$Entropy(Decision|Humidity>70) = – (4/10) * log2(4/10) – (6/10) * log2(6/10) = 0.970$

$Gain(Decision, Humidity<> 70) = 0.940 – (4/14) * (0.811) – (10/14) * (0.970) = 0.940 – 0.231 – 0.692 = 0.014$

$SplitInfo(Decision, Humidity<> 70) = -(4/14) * log2(4/14) -(10/14) * log2(10/14) = 0.863$

$GainRatio(Decision, Humidity<> 70) = 0.016$

> Check 75 as a threshold for humidity

$Entropy(Decision|Humidity<=75) = – (1/5) * log2(1/5) – (4/5) * log2(4/5) = 0.721$

$Entropy(Decision|Humidity>75) = – (4/9) * log2(4/9) – (5/9) * log2(5/9) = 0.991$

$Gain(Decision, Humidity<> 75) = 0.940 – (5/14).(0.721) – (9/14).(0.991) = 0.940 – 0.2575 – 0.637 = 0.045$

$SplitInfo(Decision, Humidity<> 75) = -(5/14) * log2(4/14) -(9/14) * log2(10/14) = 0.940$

$GainRatio(Decision, Humidity<> 75) = 0.047$

> I think calculation demonstrations are enough. Now, I skip the calculations and write only results.

$GainRatio(Decision, Humidity <> 78) = 0.090$

$GainRatio(Decision, Humidity <> 80) = 0.107$

$GainRatio(Decision, Humidity <> 85) = 0.027$

$GainRatio(Decision, Humidity <> 90) = 0.016$

$GainRatio(Decision, Humidity <> 95) = 0.128$

> Here, I ignore the value 96 as threshold because humidity cannot be greater than this value.

> As seen, gain maximizes when threshold is equal to 80 for humidity. This means that we need to compare other nominal attributes and comparison of humidity to 80 to create a branch in our tree.

---

### **Humidity** Attribute

> Temperature feature is continuous as well.

> Calculation same as Humidity

$GainRatio(Decision, Temperature<> 83) = 0.305$

---

> Let’s summarize calculated gain and gain ratios.

| Attribute         | GainRatio |
| ----------------- | --------- |
| Wind              | 0.049     |
| Outlook           | 0.155     |
| Humidity <> 80    | 0.107     |
| Temperature <> 83 | 0.305     |

> Temperature will be the root node because it has the highest gain ratio value.
